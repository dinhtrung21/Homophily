{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26088c96",
   "metadata": {},
   "source": [
    "The code is implemented as part of the project. This notebook template is a material of course CS-E4730 Computational Social Science at Aalto University, which is available for download at A+ via plus.cs.aalto.fi. The notebook also contains functions to fetch data from wikipedia and parse through some of the source data.\n",
    "\n",
    "For Wikipedia API see documentation here:\n",
    "https://pypi.org/project/Wikipedia-API/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e59646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi, time, json,requests,os\n",
    "#from tqdm import tqdm # you can import this for progress bar instead if you are not using notebooks\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def ensure_person_data():\n",
    "    \"\"\"Ensures the existence of the person-data.tsv file.\n",
    "    \n",
    "    For downloading the file 'person-data.tsv', please go to https://search.gesis.org/research_data/SDN-10.7802-1515\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the person-data.tsv file is not found in the current directory.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(\"person-data.tsv\"):\n",
    "        raise Exception(\"For downloading the file 'person-data.tsv', please go to https://search.gesis.org/research_data/SDN-10.7802-1515\")\n",
    "    \n",
    "def ensure_gender_data():\n",
    "    \"\"\"Ensures the existence of the gender data file and downloads it from a remote URL if it is not found.\n",
    "    \n",
    "    The file is downloaded from http://www.cs.cmu.edu/~ark/bio/data/wiki.genders.txt\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(\"wiki.genders.txt\"):\n",
    "        print(\"Downloading the gender data file...\")\n",
    "        open('wiki.genders.txt', 'wb').write(requests.get(\"http://www.cs.cmu.edu/~ark/bio/data/wiki.genders.txt\", allow_redirects=True).content)\n",
    "    \n",
    "    \n",
    "def filter_persons_by(occupation=None,birth_less=None,birth_more=None,nationality=None):\n",
    "    \"\"\"\n",
    "    Filters persons from the person-data.tsv file based on specified criteria.\n",
    "\n",
    "    Args:\n",
    "        occupation (str, optional): The occupation of the person. Defaults to None.\n",
    "        birth_less (int, optional): The upper bound of the birth year of the person. Defaults to None.\n",
    "        birth_more (int, optional): The lower bound of the birth year of the person. Defaults to None.\n",
    "        nationality (str, optional): The nationality of the person. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of persons that match the specified criteria. The keys are the person names and the values are \n",
    "        dictionaries containing the person's attributes.\n",
    "    \"\"\"\n",
    "    ensure_person_data()\n",
    "    pfile=open(\"person-data.tsv\",'r')\n",
    "    titles=pfile.readline().strip().split(\"\\t\")\n",
    "    i=0\n",
    "    persons={}\n",
    "    for line in pfile:\n",
    "        person=dict(zip(titles,line.strip().split(\"\\t\")))\n",
    "        if person[\"birthDate\"]=='NA':\n",
    "            birthYear=None\n",
    "        else:\n",
    "            birthDate=person[\"birthDate\"].strip(\"[]\\t' \")\n",
    "            birthYear=int(birthDate.strip(\"-\").split(\"-\")[0])\n",
    "            if birthDate[0]==\"-\":\n",
    "                birthYear=-birthYear\n",
    "        \n",
    "        occupation_ok=occupation==None or occupation in person[\"occupation\"] \n",
    "        nationality_ok=nationality==None or nationality in person[\"nationality\"] \n",
    "        birth_less_ok=birth_less==None or birthYear!=None and birthYear<birth_less\n",
    "        birth_more_ok=birth_more==None or birthYear!=None and birthYear>birth_more\n",
    "               \n",
    "        if occupation_ok and nationality_ok and birth_less_ok and birth_more_ok:\n",
    "            name=person[\"WikiURL\"][len(\"http://en.wikipedia.org/wiki/\"):]\n",
    "            persons[name]=person\n",
    "    return persons\n",
    "\n",
    "def get_genderdata():\n",
    "    \"\"\"Reads a tab-separated file containing Wikipedia article information and returns a dictionary of gender data.\n",
    "\n",
    "    The function reads a file named \"wiki.genders.txt\" and extracts the gender data for each name in the file, using the first letter of the gender field. The gender data is then stored in a dictionary with the name as the key and the gender abbreviation as the value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing gender data for each name in the file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the input file cannot be found or opened.\n",
    "\n",
    "    Example:\n",
    "        >>> gender_data = get_genderdata()\n",
    "        >>> gender_data['Albert_Einstein']\n",
    "        'M'\n",
    "    \"\"\"\n",
    "    ensure_gender_data()\n",
    "    genderdata={}\n",
    "    with open(\"wiki.genders.txt\", \"r\") as inputfile:\n",
    "        inputfile.readline()\n",
    "        for line in inputfile:\n",
    "            wid,gender,name=line.strip().split(\"\\t\")\n",
    "            name=name.replace(\" \",\"_\")\n",
    "            genderdata[name]=gender[:1]\n",
    "    return genderdata\n",
    "\n",
    "def fill_in_genders(persons):\n",
    "    \"\"\"\n",
    "    Fills in the gender information of persons in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        persons (dict): A dictionary containing information about persons.\n",
    "\n",
    "    Returns:\n",
    "        None. The function modifies the input dictionary in place.\n",
    "\n",
    "    Examples:\n",
    "        >>> persons = {'Alice': {'age': 25}, 'Bob': {'age': 30}}\n",
    "        >>> fill_in_genders(persons)\n",
    "        >>> persons\n",
    "        {'Alice': {'age': 25, 'gender': 'F'}, 'Bob': {'age': 30, 'gender': 'M'}}\n",
    "\n",
    "    \"\"\"\n",
    "    genderdata=get_genderdata()\n",
    "    for person in list(persons.keys()):\n",
    "        if person in genderdata:\n",
    "            gender=genderdata[person]\n",
    "        else:\n",
    "            gender=\"NA\"\n",
    "        persons[person][\"gender\"]=gender\n",
    "        \n",
    "def fetch_links(people,batch_size=None,lang='en'):\n",
    "    \"\"\"Uses the Wikipedia API to fetch Wikipedia links between the given people.\n",
    "    \n",
    "    The links are filled into the people dictionary in place.\n",
    "    \n",
    "    Note that only links between the people are saved, and if you want to inspect other links\n",
    "    you should write your own fetching function.\n",
    "\n",
    "    Args:\n",
    "        people (dict): A dictionary containing names of people as keys and attributes as values.\n",
    "        batch_size (int, optional): The maximum number of people to fetch links for in a single batch. Defaults to None, which means there is no maximum.\n",
    "        lang (str, optional): The language in which to fetch Wikipedia links. Defaults to 'en'.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the links were not fetched for every person due to the batch size, False otherwise.\n",
    "    \"\"\"\n",
    "    wiki = wikipediaapi.Wikipedia(lang)\n",
    "    i=0\n",
    "    print('Fetching link data from Wikipedia')\n",
    "    pbar=tqdm(total=len(people))\n",
    "    for name,attributes in people.items():\n",
    "        pbar.update(1)\n",
    "        if \"links\" not in attributes:\n",
    "            page=wiki.page(name)\n",
    "            links=list(map(lambda x:x.replace(\" \",\"_\"),page.links.keys()))\n",
    "            plinks=list(filter(lambda x:x in people,links))\n",
    "            #print(name,plinks)\n",
    "            people[name][\"links\"]=plinks\n",
    "            i+=1\n",
    "            time.sleep(0.1)\n",
    "        if i==batch_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fetch_langs(people,batch_size=None,lang='en'):\n",
    "    \"\"\"Uses the Wikipedia API to fetch list of Wikipedia language editions where each person in the people \n",
    "    dictionary appears.\n",
    "    \n",
    "    The language editions are filled into the people dictionary in place.\n",
    "\n",
    "    Args:\n",
    "        people (dict): A dictionary containing names of people as keys and attributes as values.\n",
    "        batch_size (int, optional): The maximum number of people to fetch links for in a single batch. Defaults to None, which means there is no maximum.\n",
    "        lang (str, optional): The language in which to fetch Wikipedia links. Defaults to 'en'.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the language editions were not fetched for every person due to the batch size, False otherwise.\n",
    "    \"\"\"\n",
    "    wiki = wikipediaapi.Wikipedia(lang)\n",
    "    i=0\n",
    "    print('Fetching language editions data from Wikipedia')\n",
    "    pbar=tqdm(total=len(people))\n",
    "    for name,attributes in people.items():\n",
    "        pbar.update(1)\n",
    "        if \"langs\" not in attributes:\n",
    "            page=wiki.page(name)\n",
    "            langs=list(page.langlinks.keys())\n",
    "            #print(name,langs)\n",
    "            people[name][\"langs\"]=langs\n",
    "            i+=1\n",
    "            time.sleep(0.1)\n",
    "        if i==batch_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fetch_summaries(people,batch_size=None,lang='en'):\n",
    "    \"\"\"Uses the Wikipedia API to fetch summary texts for each person in the people dictionary.\n",
    "    \n",
    "    The summary texts are filled into the people dictionary in place.\n",
    "\n",
    "    Args:\n",
    "        people (dict): A dictionary containing names of people as keys and attributes as values.\n",
    "        batch_size (int, optional): The maximum number of people to fetch links for in a single batch. Defaults to None, which means there is no maximum.\n",
    "        lang (str, optional): The language in which to fetch Wikipedia links. Defaults to 'en'.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the summaries were not fetched for every person due to the batch size, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    wiki = wikipediaapi.Wikipedia(lang)\n",
    "    i=0\n",
    "    print('Fetching summary text data from Wikipedia')\n",
    "    pbar=tqdm(total=len(people))\n",
    "    for name,attributes in people.items():\n",
    "        pbar.update(1)\n",
    "        if \"summary\" not in attributes:\n",
    "            page=wiki.page(name)\n",
    "            summary=page.summary\n",
    "            #print(name,summary)\n",
    "            people[name][\"summary\"]=summary\n",
    "            i+=1\n",
    "            time.sleep(0.1)\n",
    "        if i==batch_size:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def save_people_json(people,filename):\n",
    "    with open(filename, \"w\") as pfile: json.dump(people,pfile)\n",
    "        \n",
    "def load_people_json(filename):\n",
    "    with open(filename, \"r\") as pfile: \n",
    "        return json.load(pfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f970da",
   "metadata": {},
   "source": [
    "In the next cell, you will find the code for loading the politician data to a dictionary from the json file that you can download through A+. The commented out code was used to parse and fetch the data. You can inspect how the data was created using that code and the functions in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6f311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"politicians.json\"\n",
    "if not os.path.isfile(filename):\n",
    "    politicians=filter_persons_by(occupation=\"politician\")\n",
    "    fill_in_genders(politicians)\n",
    "    save_people_json(politicians,filename)\n",
    "    \n",
    "politicians=load_people_json(filename)\n",
    "\n",
    "## The code below fills in summaries, language editions and links from wikipedia.\n",
    "## The fetching takes place in batches of 1000 queries after which the data is saved to disk.\n",
    "#while fetch_summaries(politicians,batch_size=1000): save_people_json(politicians,filename)\n",
    "#while fetch_langs(politicians,batch_size=1000): save_people_json(politicians,filename)\n",
    "#while fetch_links(politicians,batch_size=1000): save_people_json(politicians,filename)\n",
    "#save_people_json(politicians,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e643b",
   "metadata": {},
   "source": [
    "Use the next cell to inspect how the data looks like for a single politician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712e4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#DBpURL': 'http://dbpedia.org/resource/Benedict_Calvert,_4th_Baron_Baltimore',\n",
       " 'ID': '21',\n",
       " 'WikiURL': 'http://en.wikipedia.org/wiki/Benedict_Calvert,_4th_Baron_Baltimore',\n",
       " 'gender': 'M',\n",
       " 'name': \"[' (the right honourable) ', ' the lord baltimore ']\",\n",
       " 'birthDate': \"[' 1679-03-21 ']\",\n",
       " 'deathDate': \"[' 1715-04-16 ']\",\n",
       " 'occupation': \"[' politician ']\",\n",
       " 'nationality': 'NA',\n",
       " 'party': 'NA',\n",
       " 'summary': \"Benedict Leonard Calvert, 4th Baron Baltimore (21 March 1679 – 16 April 1715) was an English nobleman and politician. He was the second son of Charles Calvert, 3rd Baron Baltimore (1637–1715) by Jane Lowe, and became his father's heir upon the death of his elder brother Cecil in 1681. The 3rd Lord Baltimore was a devout Roman Catholic, and had lost his title to the Province of Maryland shortly after the events of the Glorious Revolution in 1688, when the Protestant monarchs William III and Mary II acceded to the British throne. Benedict Calvert made strenuous attempts to have his family's title to Maryland restored by renouncing Roman Catholicism and joining the Church of England.\\nIn February 1715 Benedict became the 4th Baron Baltimore upon the death of his father, and he immediately petitioned King George I for the restoration of Maryland to his control. However, before the King could rule on the petition, Baltimore died aged 36, outliving his father by just two months. Shortly afterwards the King restored the title to Maryland to Calvert's young son Charles Calvert, 5th Baron Baltimore.\",\n",
       " 'langs': ['de', 'fr', 'ja', 'pl'],\n",
       " 'links': ['Benedict_Leonard_Calvert',\n",
       "  'Benedict_Swingate_Calvert',\n",
       "  'Charles_Calvert,_5th_Baron_Baltimore',\n",
       "  'Henry_Darnall',\n",
       "  'Sir_Robert_Eden,_1st_Baronet,_of_Maryland']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians['Benedict_Calvert,_4th_Baron_Baltimore']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e30524",
   "metadata": {},
   "source": [
    "**Revision of prior analysis**\n",
    "\n",
    "From the dictionary of politicians created above, we create a network by running a loop where for each policitians, we create edges from that politicians to the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca5850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "def construct_network():\n",
    "    \"\"\"\n",
    "    This function constructs a social network from the data of politicians.\n",
    "\n",
    "    Args: filename (str) - The filename of the politicians' data file.\n",
    "    Returns: net (nx.Graph) - A networkx graph object representing the social network.\n",
    "    \"\"\"\n",
    "    net = nx.Graph()\n",
    "    \n",
    "    for person, data in politicians.items():\n",
    "        net.add_node(person)\n",
    "        neighbors = data['links']\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor != person:\n",
    "                net.add_edge(person, neighbor)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53839ece",
   "metadata": {},
   "source": [
    "Here we calculate the graph of the network, including the numbers of nodes, edges, average degree and the clustering coefficient. Zero-degree nodes are also included for the calculation of male and female nodes' degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c29ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network has:\n",
      "6880 nodes\n",
      "10294 edges\n",
      "2.9924418604651164 average degree\n",
      "0.14363897936984674 average clustering coefficient\n",
      "7.290627875646906 average shortest path length\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "net = construct_network()\n",
    "\n",
    "# Print out some basic statistics of the network\n",
    "print(\"The network has:\")\n",
    "print(len(net), \"nodes\")\n",
    "print(net.number_of_edges(), \"edges\")\n",
    "print(2*net.number_of_edges()/len(net), \"average degree\")\n",
    "print(nx.average_clustering(net), \"average clustering coefficient\")\n",
    "print(nx.average_shortest_path_length(net.subgraph(max(nx.connected_components(net), key=len))), \"average shortest path length\")\n",
    "\n",
    "# Plot the network\n",
    "# plt.figure()\n",
    "# positions = nx.spring_layout(net)\n",
    "# nx.draw(net, positions, node_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45207c2a",
   "metadata": {},
   "source": [
    "Below is the calculation of the average degree of male nodes and female nodes. The result implies that in general female nodes have higher degrees than male nodes, indicating more nobility for the women included on Wikipedia. The average degree inequality is describe as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34c0cd",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{1}{N_F}\\sum_{i} d_{i}^F \\ge \\frac{1}{N_M}\\sum_{i} d_{i}^M\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f046dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average degree of males in the network is: 4.087830687830688\n",
      "The average degree of females in the network is: 7.176165803108808\n"
     ]
    }
   ],
   "source": [
    "male_sum = 0       # Total degree of male nodes\n",
    "male_count = 0     # Total degree of female nodes\n",
    "female_sum = 0     # Number of male nodes\n",
    "female_count = 0   # Number of female nodes\n",
    "\n",
    "# Loop through the network to calculate the average degree for each gender.\n",
    "for node in net:\n",
    "    value = politicians[node]\n",
    "    if value['gender'] == 'M':\n",
    "        male_sum += net.degree(node)\n",
    "        male_count += 1\n",
    "    elif value['gender'] == 'F':\n",
    "        female_sum += net.degree(node)\n",
    "        female_count += 1\n",
    "\n",
    "print(\"The average degree of males in the network is:\", male_sum / male_count)\n",
    "print(\"The average degree of females in the network is:\", female_sum / female_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae16ecd",
   "metadata": {},
   "source": [
    "**Gender homophily**\n",
    "\n",
    "Next we will analyse the gender homophily of our data. For simplicity for our model, the function below creates a new network with only two genders (male and female) with no self-edge and no zero-degree nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb16e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_network():\n",
    "    \"\"\"\n",
    "    This function constructs a new social network from the data of politicians, consisting of only two genders and no zero-degree nodes.\n",
    "\n",
    "    Returns: net (nx.Graph) - A networkx graph object representing the social network.\n",
    "    \"\"\"\n",
    "    net = nx.Graph()\n",
    "    \n",
    "    for person, data in politicians.items():\n",
    "        if data['gender'] != 'NA':         # Only consider politicians that are either male or female\n",
    "            neighbors = data['links']\n",
    "            for neighbor in neighbors:\n",
    "                nei_gender = politicians[neighbor]['gender']\n",
    "                if neighbor != person and nei_gender != 'NA':\n",
    "                    net.add_edge(person, neighbor)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ac454",
   "metadata": {},
   "source": [
    "The codes below create the new network defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e7e8414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new network has:\n",
      "1573 nodes\n",
      "5736 edges\n",
      "7.293070565797839 average degree\n",
      "0.339796557267688 average clustering coefficient\n",
      "6.817727056393223 average shortest path length\n"
     ]
    }
   ],
   "source": [
    "new_net = binary_network()\n",
    "\n",
    "print(\"The new network has:\")\n",
    "print(len(new_net), \"nodes\")\n",
    "print(new_net.number_of_edges(), \"edges\")\n",
    "print(2*new_net.number_of_edges()/len(new_net), \"average degree\")\n",
    "print(nx.average_clustering(new_net), \"average clustering coefficient\")\n",
    "print(nx.average_shortest_path_length(new_net.subgraph(max(nx.connected_components(new_net), key=len))), \"average shortest path length\")\n",
    "\n",
    "# Plot the network\n",
    "# plt.figure()\n",
    "# positions = nx.spring_layout(new_net)\n",
    "# nx.draw(new_net, positions, node_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20471626",
   "metadata": {},
   "source": [
    "First we can check that for our new network, notability difference between male and female still applies by the calculation of inequality (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fa5e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average degree of males in the new network is: 6.66908037653874\n",
      "The average degree of females in the new network is: 11.78125\n"
     ]
    }
   ],
   "source": [
    "new_male_sum = 0\n",
    "new_male_count = 0\n",
    "new_female_sum = 0\n",
    "new_female_count = 0\n",
    "\n",
    "for node in new_net:\n",
    "    value = politicians[node]\n",
    "    if value['gender'] == 'M':\n",
    "        new_male_sum += new_net.degree(node)\n",
    "        new_male_count += 1\n",
    "    elif value['gender'] == 'F':\n",
    "        new_female_sum += new_net.degree(node)\n",
    "        new_female_count += 1\n",
    "\n",
    "print(\"The average degree of males in the new network is:\", new_male_sum / new_male_count)\n",
    "print(\"The average degree of females in the new network is:\", new_female_sum / new_female_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0691587",
   "metadata": {},
   "source": [
    "Next we analyse the homophily of the whole network and for each gender. For the full explanation please refer to the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d778d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_count = 0\n",
    "mm_count = 0\n",
    "ff_count = 0\n",
    "\n",
    "# Empirical network data between men and women\n",
    "for edge in list(new_net.edges):                 # Loop through every edges (connections) between the politicians\n",
    "    name_1, name_2 = edge                    # Get the name of the two politicians in the edge\n",
    "    gender_1, gender_2 = politicians[name_1]['gender'], politicians[name_2]['gender'] # Get the gender of the politicians\n",
    "    concat = gender_1 + gender_2             # Create a concatenation of the two genders\n",
    "    if concat == 'FM' or concat == 'MF':     # A connection between different genders can only be a man-woman connection and vice-versa\n",
    "        fm_count += 1\n",
    "    elif concat == 'MM':\n",
    "        mm_count += 1\n",
    "    elif concat == 'FF':\n",
    "        ff_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b392a00",
   "metadata": {},
   "source": [
    "The analysis of our network homophily, which is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83e598",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "e_{FM} - \\bar{e}_{FM} = \\frac{E}{3} - \\bar{e}_{FM} > 0.1e_{FM} = 191.2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba205fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net.number_of_edges()/3 - fm_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c85cce",
   "metadata": {},
   "source": [
    "The analysis of male homophily, which is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96a142",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\bar{e}_{FM}}{\\bar{e}_{MM} + \\bar{e}_{FM}} < 0.45\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e12ee32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2994830132939439"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_count/(fm_count + mm_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ac3d1",
   "metadata": {},
   "source": [
    "Similarly, the analysis for female homophily is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19336a",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\bar{e}_{FM}}{\\bar{e}_{FF} + \\bar{e}_{FM}} < 0.45\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7ee5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835221421215242"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_count/(fm_count + ff_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
